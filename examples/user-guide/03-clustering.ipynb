{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a117aae9-149d-4cea-bc33-f7a5f04eb2bd",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "When you don't know the groups beforehand, clustering gathers similar observations into groups according to the geometry of data scatters, like penguins shuffle themselves into clusters according to how they look. This notebook covers three main clustering approaches.\n",
    "\n",
    "| Method | Type | How it works | Best for |\n",
    "|--------|------|--------------|----------|\n",
    "| **Hierarchical Clustering (HCA)** | Bottom-up | Builds a tree of nested clusters | Exploring relationships, small-medium datasets |\n",
    "| **K-Means** | Partition-based | Assigns points to K cluster centers | Large datasets, spherical clusters, when K is known |\n",
    "| **DBSCAN** | Density-based | Finds dense regions separated by low-density areas | Arbitrary shapes, automatic cluster count, outlier detection |\n",
    "\n",
    "Let's explore all three methods using the penguins dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "012328b0-384b-453b-b1fc-6e310e881574",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Module not found \"file:///C:/Users/parse01/documents-locaux/GitHub/ds/src/ml/estimators/HDBSCAN.js\".\n    at \u001b[0m\u001b[36mfile:///C:/Users/parse01/documents-locaux/GitHub/ds/src/ml/index.js\u001b[0m:\u001b[0m\u001b[33m48\u001b[0m:\u001b[0m\u001b[33m25\u001b[0m",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "TypeError: Module not found \"file:///C:/Users/parse01/documents-locaux/GitHub/ds/src/ml/estimators/HDBSCAN.js\".",
      "    at \u001b[0m\u001b[36mfile:///C:/Users/parse01/documents-locaux/GitHub/ds/src/ml/index.js\u001b[0m:\u001b[0m\u001b[33m48\u001b[0m:\u001b[0m\u001b[33m25\u001b[0m",
      "    at async <anonymous>:6:12"
     ]
    }
   ],
   "source": [
    "// Setup DOM for plotting in Jupyter with Deno\n",
    "import { Window } from 'https://esm.sh/happy-dom@12.10.3';\n",
    "const window = new Window();\n",
    "globalThis.document = window.document;\n",
    "globalThis.HTMLElement = window.HTMLElement;\n",
    "\n",
    "// import packages\n",
    "import * as ds from \"../../src/index.js\";\n",
    "import * as Plot from \"@observablehq/plot\";\n",
    "import * as d3 from 'npm:d3'\n",
    "\n",
    "// data\n",
    "const penguinsResponse = await fetch(\n",
    "  'https://cdn.jsdelivr.net/npm/vega-datasets@2/data/penguins.json',\n",
    ");\n",
    "const penguinsDataRaw = await penguinsResponse.json();\n",
    "const penguinsData = penguinsDataRaw // there is a row with a \".\" instead of null in the Sex field\n",
    "  .map(row => row.Sex === '.' ? { ...row, Sex: null } : row)\n",
    "  .filter(row => row.Sex);\n",
    "\n",
    "console.table(penguinsData.slice(0, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7440fe7d-9202-4453-a9b3-594e2acac59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "const numeric_fields = [\n",
    "  \"Beak Length (mm)\",\n",
    "  \"Beak Depth (mm)\",\n",
    "  \"Flipper Length (mm)\",\n",
    "  \"Body Mass (g)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f7a26f-d88b-4574-aa5f-f918eed7651e",
   "metadata": {},
   "source": [
    "## Hierarchical clustering\n",
    "\n",
    "Start with every penguin alone. Then, step by step, the most resembling individuals regroup, then the closest groups regroup and so on until they become a single group. Each merge creates a branch, and together they form a hierarchical dendrogram, a family tree of similarity. There is no unique way to group individuals. Different linkage functions exist for different purposes.\n",
    "\n",
    "| Linkage      | What it means                                              | Typical use case                                                                                                                           |\n",
    "| ------------ | ---------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------ |\n",
    "| Single   | distance between nearest neighbors                     | To find elongated or chain-like clusters (e.g. rivers, coastlines). Sensitive to noise and chaining effects.                  |\n",
    "| Complete | distance between farthest points                       | Produces compact, evenly sized clusters; robust to outliers. Useful when you want tight, clearly separated groups.                 |\n",
    "| Average  | mean distance between all pairs of points              | A balanced compromise between Single and Complete; works well for moderate noise or when cluster shapes are mixed.                 |\n",
    "| Ward     | merges clusters that increase total variance the least | Favors spherical, equally sized clusters; ideal for quantitative variables and often used in ecological or morphological data. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c9cc9be-952b-4f6f-b0e8-c33aa13bd87a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReferenceError",
     "evalue": "d3 is not defined",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "ReferenceError: d3 is not defined",
      "    at <anonymous>:1:45"
     ]
    }
   ],
   "source": [
    "const penguinsSample = d3.shuffle(penguinsData.slice()).slice(0, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "434f8da3-31cc-44b3-9626-849e6ea99ced",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReferenceError",
     "evalue": "ds is not defined",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "ReferenceError: ds is not defined",
      "    at <anonymous>:1:43"
     ]
    }
   ],
   "source": [
    "const hcaEstimator = new ds.ml.HCA({\n",
    "    linkage: \"ward\" // Options: 'single', 'complete', 'average', 'ward'\n",
    "});\n",
    "hcaEstimator.fit({\n",
    "    data: penguinsSample,\n",
    "    X: numeric_fields\n",
    "});\n",
    "undefined; // to avoid large output from jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc1fe7bd-c9d0-4004-97c1-7ea6c8b1cfc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReferenceError",
     "evalue": "ds is not defined",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "ReferenceError: ds is not defined",
      "    at <anonymous>:1:49"
     ]
    }
   ],
   "source": [
    "const dendrogramRenderer = ds.plot.createD3DendrogramRenderer(d3, {\n",
    "  distanceScale: \"log10\",\n",
    "  labelOrientation: \"horizontal\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "279fa750-9cf0-4ef5-8f2d-0bb903496120",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReferenceError",
     "evalue": "ds is not defined",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "ReferenceError: ds is not defined",
      "    at <anonymous>:1:22"
     ]
    }
   ],
   "source": [
    "ds.plot.plotHCA(hcaEstimator.model).show(dendrogramRenderer, {\n",
    "  config: { orientation: \"horizontal\", height: 800 }\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "axwvl9wmu6h",
   "metadata": {},
   "source": [
    "The dendrogram is a tree diagram showing how clusters diverge from left to right (or merged from rigth to left). The length of the ranches indicate the group variance. To obtain the grouping, you either cut at a chosen height of the dendrogram, or selecting the number of group you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2a91a64-c347-4e5b-99d0-1671611cbcda",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReferenceError",
     "evalue": "hcaEstimator is not defined",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "ReferenceError: hcaEstimator is not defined",
      "    at <anonymous>:1:40"
     ]
    }
   ],
   "source": [
    "const hcaLabels = hcaEstimator.cut(3) // Cut into N clusters, cutHeight(N) can also be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d96c9e7-1b87-4ea5-9e06-62e46cc907d9",
   "metadata": {},
   "source": [
    "### Silhouette\n",
    "\n",
    "To check how well each penguin fits its assigned group, we can compute a silhouette score with\n",
    "\n",
    "$$\n",
    "s_i = \\frac{b_i - a_i}{\\max(a_i, b_i)},\n",
    "$$\n",
    "\n",
    "where $a_i$ is the average distance to its own cluster and $b_i$ is the average distance to the nearest other cluster.\n",
    "\n",
    "Values close to 1 mean the penguin is comfortably inside its group. Values near 0 mean it stands on the border. Negative values mean it might prefer another flock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3d1192c-a1db-4dde-93df-1a1a3319284a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReferenceError",
     "evalue": "ds is not defined",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "ReferenceError: ds is not defined",
      "    at <anonymous>:1:45"
     ]
    }
   ],
   "source": [
    "const silhouettePlot = ds.ml.silhouette.silhouetteSamples(\n",
    "  {\n",
    "    data: penguinsSample,\n",
    "    columns: numeric_fields // the numeric columns you clustered on\n",
    "  },\n",
    "  hcaLabels\n",
    ")\n",
    "\n",
    "ds.plot\n",
    "  .plotSilhouette({ samples: silhouettePlot }, { height: 800 })\n",
    "  .show(Plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b645e74c-1f67-45a1-89ef-c3fbf0b4f143",
   "metadata": {},
   "source": [
    "## K-Means clustering\n",
    "\n",
    "You place each penguin in the variable space according to their characteristics. The you scatter *k* pebbles among the penguins. You assign each penguin to the closest pebble, then you measure the distances between the penguins and their closest pebble. You sequentially move the pebbles to minimize the distances.\n",
    "\n",
    "Here are the steps\n",
    "\n",
    "1. Randomly place K cluster centers (centroids)\n",
    "2. Assign each point to the nearest centroid\n",
    "3. Recalculate centroids as the mean of assigned points\n",
    "4. Repeat steps 2-3 until convergence (centroids stop moving)\n",
    "\n",
    "The key parameters are\n",
    "\n",
    "- `k`: Number of clusters (must be specified!)\n",
    "- `max_iter`: Maximum iterations before stopping\n",
    "- `tol`: Convergence tolerance (stop when centroid movement < tol)\n",
    "- `random_state`: Seed for reproducibility (K-means is random!)\n",
    "- `standardize`: Scale features to same range (critical when mixing units like mm and grams!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8a85822-086c-45f5-a674-fbd281e06889",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReferenceError",
     "evalue": "ds is not defined",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "ReferenceError: ds is not defined",
      "    at <anonymous>:1:46"
     ]
    }
   ],
   "source": [
    "const kmeansEstimator = new ds.ml.KMeans({\n",
    "    k: 3,\n",
    "    max_iter: 300,\n",
    "    tol: 1e-4,\n",
    "    random_state: 42\n",
    "}).fit({\n",
    "    data: penguinsData,\n",
    "    columns: numeric_fields,\n",
    "    standardize: true // to compare different metrics, like mm and grams\n",
    "});\n",
    "undefined;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e66699c-7a2a-4103-a6ad-f6dd8cf70ed8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReferenceError",
     "evalue": "penguinsData is not defined",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "ReferenceError: penguinsData is not defined",
      "    at <anonymous>:1:49"
     ]
    }
   ],
   "source": [
    "const penguinsWithLabels = penguinsData.map((d, i) => ({\n",
    "  ...d,\n",
    "  clusterK: String(\"Group \" + kmeansEstimator.labels[i])\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0ea6e56-7706-4f65-98d0-1b3df4fd9afd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReferenceError",
     "evalue": "ds is not defined",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "ReferenceError: ds is not defined",
      "    at <anonymous>:1:43"
     ]
    }
   ],
   "source": [
    "const pcaEstimator = new ds.mva.PCA({\n",
    "    nComponents: 2,\n",
    "    scale: true,\n",
    "    center: true,\n",
    "    scaling: 1\n",
    "}).fit({\n",
    "    data: penguinsData\n",
    "});\n",
    "\n",
    "ds.plot.ordiplot(pcaEstimator.model, {\n",
    "  colorBy: penguinsWithLabels.map((d) => d.clusterK)\n",
    "}).show(Plot);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e66a07-9a84-4a1b-9b15-44fa5dbb4444",
   "metadata": {},
   "source": [
    "We used a PCA to visualize the clusters in 2D space. The colors show the K-means cluster assignments. We should look for\n",
    "\n",
    "- tight, separated groups: Good clustering—groups are distinct,\n",
    "- overlapping colors: Some ambiguity—observations on cluster boundaries, and\n",
    "- cluster size: Are groups roughly balanced, or is one cluster much larger.\n",
    "\n",
    "Clustering is exploratory—there's no single \"correct\" answer. The best clustering depends on your research question and domain knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "z6domev9in",
   "metadata": {},
   "source": [
    "## DBSCAN\n",
    "\n",
    "Unlike K-Means and HCA, DBSCAN (Density-Based Spatial Clustering of Applications with Noise) doesn't require you to specify the number of clusters beforehand. Instead, it discovers clusters by finding dense regions in the data. Penguins that are closed together (high density) belong to the same cluster, and lone penguins wandering far from any flock are considered outliers (noise).\n",
    "\n",
    "Here is how DBSCAN works, step by step.\n",
    "\n",
    "1. For each penguin, count how many other penguins are within `eps` distance (the neighborhood radius)\n",
    "2. If a penguin has at least `minSamples` neighbors, it's a **core point** (part of a dense region)\n",
    "3. Penguins that can reach a core point (within `eps`) join that cluster\n",
    "4. Penguins that can't reach any cluster are labeled as noise (outliers)\n",
    "\n",
    "DBSCAN are almost always better than k-means. They automatically determines the number of clusters (very sensible to the parameters, though), they find arbitrarily shaped clusters (not just spherical), they identify outliers as noise and they are deterministic (same result every time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aywr7i7r716",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReferenceError",
     "evalue": "ds is not defined",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "ReferenceError: ds is not defined",
      "    at <anonymous>:2:16"
     ]
    }
   ],
   "source": [
    "// First, let's standardize the features since eps is distance-based\n",
    "const scaler = new ds.ml.preprocessing.StandardScaler().fit({\n",
    "  data: penguinsData,\n",
    "  columns: numeric_fields\n",
    "});\n",
    "\n",
    "const penguinsScaled = scaler.transform({\n",
    "  data: penguinsData,\n",
    "  columns: numeric_fields\n",
    "});\n",
    "\n",
    "// Fit DBSCAN\n",
    "const dbscanEstimator = new ds.ml.DBSCAN({\n",
    "  eps: 0.65,        // Experiment with this: smaller = tighter clusters\n",
    "  minSamples: 10    // Minimum points to form a dense region\n",
    "});\n",
    "\n",
    "dbscanEstimator.fit({\n",
    "  data: penguinsScaled.data,\n",
    "  columns: numeric_fields\n",
    "});\n",
    "\n",
    "// Check what DBSCAN found\n",
    "dbscanEstimator.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7pm0hqr3vjr",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReferenceError",
     "evalue": "penguinsData is not defined",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "ReferenceError: penguinsData is not defined",
      "    at <anonymous>:3:28"
     ]
    }
   ],
   "source": [
    "// Visualize DBSCAN clusters\n",
    "// Label -1 means noise, 0+ means cluster ID\n",
    "const penguinsWithDBSCAN = penguinsData.map((d, i) => ({\n",
    "  ...d,\n",
    "  clusterDBSCAN: dbscanEstimator.labels[i] === -1 \n",
    "    ? 'Noise' \n",
    "    : String('Cluster ' + (dbscanEstimator.labels[i]))\n",
    "}));\n",
    "\n",
    "ds.plot.ordiplot(pcaEstimator.model, {\n",
    "  colorBy: penguinsWithDBSCAN.map((d) => d.clusterDBSCAN)\n",
    "}).show(Plot);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xnwzef596cf",
   "metadata": {},
   "source": [
    "As said, the class attribution highly depends on the two key parameters. When  the neighborhood radius `eps` is too high, points merge into few clusters - too small, everything becomes noise or tiny clusters. Penguins is a fictive case, where we have the species information, in theory using DBSCAN on them doesn't make much sense outside understanding the method. In real cases, plotting the distribution of pairwise distances might help to set a reliable `eps`. When the minimum points for a dense region `minSamples` is too small, noise becomes clusters, ans when it's too large, real clusters become noise. Rule of thumb, use `minSamples ≥ dimensions + 1` (for 4 features, try 5-10). More stable clustering can be made with HDBSCAN (hierarchical DBSCAN), but `tangent/ds` doesn't have it yet. For more stability, multiple clustering methods can be used with an *ensemble* perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rfg0ygglhne",
   "metadata": {},
   "source": [
    "## Ensemble clustering\n",
    "\n",
    "Different clustering algorithms may find different patterns in the data. Instead of choosing one, we can combine multiple models to get more robust, consensus clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ofx2wexyja",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReferenceError",
     "evalue": "ds is not defined",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "ReferenceError: ds is not defined",
      "    at <anonymous>:2:26"
     ]
    }
   ],
   "source": [
    "// Create ensemble with different clustering algorithms\n",
    "const consensusCluster = new ds.ml.ConsensusCluster({\n",
    "  clusterers: [\n",
    "    new ds.ml.KMeans({ k: 3, random_state: 42 }),\n",
    "    new ds.ml.DBSCAN({ eps: 0.8, minSamples: 5 }),\n",
    "  ],\n",
    "  finalClusterer: new ds.ml.HCA({ linkage: 'average' })  // Cluster the co-association matrix\n",
    "});\n",
    "\n",
    "// Fit ensemble\n",
    "consensusCluster.fit({\n",
    "  data: penguinsScaled.data,\n",
    "  columns: numeric_fields\n",
    "});\n",
    "\n",
    "consensusCluster.summary();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "wiwb86e17bm",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReferenceError",
     "evalue": "penguinsData is not defined",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "ReferenceError: penguinsData is not defined",
      "    at <anonymous>:2:31"
     ]
    }
   ],
   "source": [
    "// Visualize consensus clusters\n",
    "const penguinsWithConsensus = penguinsData.map((d, i) => ({\n",
    "  ...d,\n",
    "  clusterConsensus: consensusCluster.labels[i] === -1 \n",
    "    ? 'Noise' \n",
    "    : String('Cluster ' + consensusCluster.labels[i])\n",
    "}));\n",
    "\n",
    "ds.plot.ordiplot(pcaEstimator.model, {\n",
    "  colorBy: penguinsWithConsensus.map(d => d.clusterConsensus)\n",
    "}).show(Plot);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2amiffhwf2f",
   "metadata": {},
   "source": [
    "The ensemble clustering fits each model, builds a co-association matrix (for each pair of points, count how many models put them in the same cluster), converts to agreement ratio (0 = never together, 1 = always together) amd finally clusters the similarity matrix using the final clusterer. The result more robust and less sensible than any single algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8ff375-c2c8-4a50-b23c-6dff26a663f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
