{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "327b6b9b-ceb7-4b41-b54e-a0216e26ca0e",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "Until now, we worked as detectives to understand what happened through our experimentations with a statistical inference *detective* mode, with the hat of someone trying to fugure out what happened suring the experiment. Now let's take the role of the *oracle* to predict future occurrences with machine learning. Machine learning models are usually declined in two major categories: classification to predict categories, and regression to poredict continuous numbers. `tangent/ds` currently support KNN, decision trees, random forests and multi-layered perceptrons (sequential neural networks).\n",
    "\n",
    "The ML workflow is often done in 7 steps.\n",
    "\n",
    "1. Split data into train/test sets\n",
    "2. Preprocess features (scaling, encoding)\n",
    "3. Cross-validate to estimate performance\n",
    "4. Tune hyperparameters to find the best model settings\n",
    "5. Fit final model on training data\n",
    "6. Evaluate on test data (data the model has never seen!)\n",
    "7. Predict on new observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304eb655-48ce-4292-800b-6503acc4f1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌───────┬──────────┬─────────────┬──────────────────┬─────────────────┬─────────────────────┬───────────────┬──────────┐\n",
      "│ (idx) │ Species  │ Island      │ Beak Length (mm) │ Beak Depth (mm) │ Flipper Length (mm) │ Body Mass (g) │ Sex      │\n",
      "├───────┼──────────┼─────────────┼──────────────────┼─────────────────┼─────────────────────┼───────────────┼──────────┤\n",
      "│     0 │ \u001b[32m\"Adelie\"\u001b[39m │ \u001b[32m\"Torgersen\"\u001b[39m │ \u001b[33m39.1\u001b[39m             │ \u001b[33m18.7\u001b[39m            │ \u001b[33m181\u001b[39m                 │ \u001b[33m3750\u001b[39m          │ \u001b[32m\"MALE\"\u001b[39m   │\n",
      "│     1 │ \u001b[32m\"Adelie\"\u001b[39m │ \u001b[32m\"Torgersen\"\u001b[39m │ \u001b[33m39.5\u001b[39m             │ \u001b[33m17.4\u001b[39m            │ \u001b[33m186\u001b[39m                 │ \u001b[33m3800\u001b[39m          │ \u001b[32m\"FEMALE\"\u001b[39m │\n",
      "│     2 │ \u001b[32m\"Adelie\"\u001b[39m │ \u001b[32m\"Torgersen\"\u001b[39m │ \u001b[33m40.3\u001b[39m             │ \u001b[33m18\u001b[39m              │ \u001b[33m195\u001b[39m                 │ \u001b[33m3250\u001b[39m          │ \u001b[32m\"FEMALE\"\u001b[39m │\n",
      "│     3 │ \u001b[32m\"Adelie\"\u001b[39m │ \u001b[32m\"Torgersen\"\u001b[39m │ \u001b[33m36.7\u001b[39m             │ \u001b[33m19.3\u001b[39m            │ \u001b[33m193\u001b[39m                 │ \u001b[33m3450\u001b[39m          │ \u001b[32m\"FEMALE\"\u001b[39m │\n",
      "│     4 │ \u001b[32m\"Adelie\"\u001b[39m │ \u001b[32m\"Torgersen\"\u001b[39m │ \u001b[33m39.3\u001b[39m             │ \u001b[33m20.6\u001b[39m            │ \u001b[33m190\u001b[39m                 │ \u001b[33m3650\u001b[39m          │ \u001b[32m\"MALE\"\u001b[39m   │\n",
      "└───────┴──────────┴─────────────┴──────────────────┴─────────────────┴─────────────────────┴───────────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "// Setup DOM for plotting in Jupyter with Deno\n",
    "import { Window } from 'https://esm.sh/happy-dom@12.10.3';\n",
    "const window = new Window();\n",
    "globalThis.document = window.document;\n",
    "globalThis.HTMLElement = window.HTMLElement;\n",
    "\n",
    "// import packages\n",
    "import * as ds from '../../src/index.js';\n",
    "import * as Plot from '@observablehq/plot';\n",
    "\n",
    "// data\n",
    "const penguinsResponse = await fetch(\n",
    "  'https://cdn.jsdelivr.net/npm/vega-datasets@2/data/penguins.json',\n",
    ");\n",
    "const penguinsDataRaw = await penguinsResponse.json();\n",
    "const penguinsData = penguinsDataRaw // there is a row with a \".\" instead of null in the Sex field\n",
    "  .map(row => row.Sex === '.' ? { ...row, Sex: null } : row)\n",
    "  .filter(row => row.Sex);\n",
    "\n",
    "console.table(penguinsData.slice(0, 5));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab200a6-c9d4-4cef-af3b-dd4a9627a851",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "We have not finished with our lovely penguins. Here we use their numerical characteristics to predict the species, which is a classification task: given measurements (beak length, flipper length, etc.), predict which species a penguin belongs to. This is supervised learning — we know the true labels and train the model to recognize patterns that distinguish species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74760eb1-80e6-4c17-bbf7-2d12d7c5af06",
   "metadata": {},
   "outputs": [],
   "source": [
    "const penguinsFeatureFields = [\n",
    "  \"Beak Length (mm)\",\n",
    "  \"Beak Depth (mm)\",\n",
    "  \"Flipper Length (mm)\",\n",
    "  \"Body Mass (g)\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d487cbd8-ad9f-4809-80f8-9fbcf403a902",
   "metadata": {},
   "source": [
    "### 1. Split and 2. scale\n",
    "\n",
    "The ML workflow includes splitting data in a training set and a testing set, so that we are able to detect overfitting - if the model performs well on training but poorly on testing, it memorized rather than learned. Scale numeric features is often done using z-scores (standardization), which returns variables with a mean of zero and a variance of 1.\n",
    "\n",
    "$$\n",
    "z = (x - mean) / std\n",
    "$$\n",
    "\n",
    "Critical for distance-based models (KNN, MLP) so that large-scale features (e.g., body mass in grams) don't dominate small-scale features (e.g., beak length in mm). Importantly, fit the scaler on training data only, then transform both train and test with the same parameters. You will often see tutorials scaling the data on the whole set, but it's a form of test data leakage which must be avoided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aea572e-9258-45e1-b1b4-1060e7b00734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "// 1. Split once so you get both arrays and table views\n",
    "const penguinsSplit = ds.ml.validation.trainTestSplit(\n",
    "  { data: penguinsData, X: penguinsFeatureFields, y: 'Species' },\n",
    "  { ratio: 0.7, shuffle: true, seed: 42 }\n",
    ");\n",
    "\n",
    "// 2. Fit the scaler on TRAIN rows only, then transform train/test\n",
    "const penguinScaler = new ds.ml.preprocessing.StandardScaler()\n",
    "  .fit({ data: penguinsSplit.train.data, columns: penguinsFeatureFields });\n",
    "\n",
    "const penguinsTrainScaled = penguinScaler.transform({\n",
    "  data: penguinsSplit.train.data,\n",
    "  columns: penguinsFeatureFields,\n",
    "  encoders: penguinsSplit.train.metadata.encoders\n",
    "});\n",
    "\n",
    "const penguinsTestScaled = penguinScaler.transform({\n",
    "  data: penguinsSplit.test.data,\n",
    "  columns: penguinsFeatureFields,\n",
    "  encoders: penguinsSplit.train.metadata.encoders\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd916907-6a83-47d7-8fb3-a8734126a4ae",
   "metadata": {},
   "source": [
    "### 3. Cross-validation\n",
    "\n",
    "Cross-validation estimates how well the model will perform on unseen data. It doesn't create a final model, just evaluate what we should expect from our model.\n",
    "\n",
    "How k-fold CV works with k=5\n",
    "\n",
    "1. Split data into 5 equal folds\n",
    "2. Train on 4 folds, test on 1 fold → get accuracy score\n",
    "3. Rotate which fold is the test set\n",
    "4. Repeat 5 times → 5 accuracy scores\n",
    "5. Average the scores for overall performance estimate\n",
    "\n",
    "Each score is accuracy (fraction of correct predictions) on a different fold. Consistency across folds means a stable model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4407458c-081f-41eb-b229-31d3d3ea30ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  \u001b[33m0.7575757575757576\u001b[39m,\n",
       "  \u001b[33m0.8181818181818182\u001b[39m,\n",
       "  \u001b[33m0.7424242424242424\u001b[39m,\n",
       "  \u001b[33m0.7878787878787878\u001b[39m,\n",
       "  \u001b[33m0.782608695652174\u001b[39m\n",
       "]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const penguinsKnnCV = ds.ml.validation.crossValidate(\n",
    "    (Xtr, ytr) => new ds.ml.KNNClassifier({ k: 5 }).fit(Xtr, ytr),\n",
    "    (model, Xte, yte) => ds.ml.metrics.accuracy(yte, model.predict(Xte)),\n",
    "    { data: penguinsData, X: penguinsFeatureFields, y: 'Species' },\n",
    "    { k: 5, shuffle: true }\n",
    ");\n",
    "penguinsKnnCV.scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2fa96e-8b0a-47ae-a4c5-54af16fdff51",
   "metadata": {},
   "source": [
    "### 4: Hyperparameter tuning\n",
    "\n",
    "Hyperparameters are settings we choose before training (not learned from data). This step is optional, and is often discarded for large models. \n",
    "\n",
    "For KNN\n",
    "\n",
    "- `k`: Number of neighbors to consider (5, 10, 20, 30..., small numbers being more sensitive to local patterns, risking overfitting)\n",
    "- `weight`: How to weight neighbors\n",
    "  - `uniform`: All neighbors vote equally\n",
    "  - `distance`: Closer neighbors have more influence\n",
    "\n",
    "Grid search tries all combinations:\n",
    "\n",
    "- 4 values of k × 2 weight options = 8 total combinations\n",
    "- For each combination, run 5-fold cross-validation\n",
    "- Pick the combination with the highest average CV score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c3a312-a770-42f5-89d2-3044240d9b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "// param grid to try\n",
    "const penguinsParamGrid = {\n",
    "  k: [5, 10, 20, 30],\n",
    "  weight: ['uniform', 'distance']\n",
    "};\n",
    "\n",
    "// grid-search on the TRAIN set only\n",
    "const penguinsGrid = ds.ml.tuning.GridSearchCV(\n",
    "  (Xtr, ytr, params) => new ds.ml.KNNClassifier(params).fit(Xtr, ytr), // the estimator function\n",
    "  (model, Xte, yte) => ds.ml.metrics.accuracy(yte, model.predict(Xte)), // the scoring function\n",
    "  { data: penguinsTrainScaled.data, X: penguinsFeatureFields, y: 'Species' }, // declarative train descriptor\n",
    "  null,                                                // no separate y array\n",
    "  penguinsParamGrid,\n",
    "  { k: 5, shuffle: true, verbose: false }              // CV options\n",
    ");\n",
    "\n",
    "console.log('Best params', penguinsGrid.bestParams);\n",
    "console.log('Best CV accuracy', penguinsGrid.bestScore);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b36215-969a-43c9-8863-51cc18cc95e0",
   "metadata": {},
   "source": [
    "And fit the model with the best hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8297384-c031-4cc4-a402-8d56725c539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "const penguinsTunedModel = new ds.ml.KNNClassifier(penguinsGrid.bestParams).fit({\n",
    "    data: penguinsTrainScaled.data,\n",
    "    X: penguinsFeatureFields,\n",
    "    y: 'Species',\n",
    "    encoders: penguinsTrainScaled.metadata.encoders\n",
    "});"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859deb36-f2c0-4311-be3b-42f0301f134e",
   "metadata": {},
   "source": [
    "### 5. Predict\n",
    "\n",
    "The model can predict in different formats:\n",
    "- **`.predict()`**: Returns class labels (integers or strings if encoder provided)\n",
    "- **`.predictProba()`**: Returns probabilities for each class (useful for uncertainty quantification)\n",
    "\n",
    "KNN makes predictions by\n",
    "\n",
    "1. Finding the k nearest neighbors in the training data (using Euclidean distance)\n",
    "2. Looking at their labels\n",
    "3. Voting: majority class wins (or weighted by distance)\n",
    "\n",
    "For a new penguin with certain measurements, KNN finds its 10 nearest neighbors in the variable space. If 7 are Gentoo, 2 are Adelie and 1 is Chinstrap, it predicts Gentoo with a 70% probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56231c3-272f-4170-bb4b-7b173197db9e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "const penguinsPredSpecies = penguinsTunedModel.predict({\n",
    "  data: penguinsTestScaled.data,\n",
    "  X: penguinsFeatureFields,\n",
    "  encoders: penguinsTestScaled.metadata.encoders\n",
    "});\n",
    "penguinsPredSpecies;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a18498f-0410-4ee3-a53c-84a09c975720",
   "metadata": {},
   "source": [
    "### 6. Evaluate the model\n",
    "\n",
    "For classifications, the confusion matrix shows where the model succeeds and fails.\n",
    "\n",
    "- Rows are the true labels (what the penguin actually is).\n",
    "- Columns are Predicted labels (what the model guessed).\n",
    "- The diagonal are the correct predictions (darker = more correct).\n",
    "- The off-diagonal show miscategorization (where the model confused one species for another).\n",
    "\n",
    "(Sum of diagonal) / (Total predictions) = (48+17+37) / 103 ≈ 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d461bb7-130b-40cb-aabf-c61c73fe8690",
   "metadata": {},
   "outputs": [],
   "source": [
    "const penguinsTrueSpecies = penguinsSplit.test.data.map(row => row.Species);\n",
    "ds.plot.plotConfusionMatrix(penguinsTrueSpecies, penguinsPredSpecies).show(Plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e37e695-aaae-45fb-af43-27d25050e28b",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "Let's leave the penguins behind to demonstrate regression for predicting diamond price, a continuous numer, based on physical characteristics (carat, cut, color, clarity, dimensions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f2558b-d09a-400c-826c-bd07d8542076",
   "metadata": {},
   "outputs": [],
   "source": [
    "const aq = await import('https://cdn.jsdelivr.net/npm/arquero@latest/+esm');\n",
    "const url = \"https://raw.githubusercontent.com/tidyverse/ggplot2/e594b49fdd5e4d95bf1031edaf6c7ccfc0cdedb0/data-raw/diamonds.csv\";\n",
    "const diamondsTable = await aq.loadCSV(url);\n",
    "console.table(diamondsTable.objects().slice(0, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a550ba4-5b71-45e3-89b9-df710f869953",
   "metadata": {},
   "source": [
    "Diamonds data has mixed types, which should be carefully treated.\n",
    "\n",
    "1. Ordinal encoding for `cut` (ordered category):\n",
    "- Fair < Good < Very Good < Premium < Ideal\n",
    "- Map to numbers: 0, 1, 2, 3, 4\n",
    "- Preserves the ordering (better cuts = higher numbers)\n",
    "\n",
    "2. Fix data type for `depth` stored as string\n",
    "- Convert \"61.5\" to the float 61.5\n",
    "\n",
    "3. One-hot encoding for `color` and `clarity` (nominal categories):\n",
    "- No natural ordering (D is not \"more\" than E)\n",
    "- Create binary columns: color_D, color_E, color_F, etc.\n",
    "- Example: color=\"E\" → [0, 1, 0, 0, 0, 0, 0]\n",
    "\n",
    "First, let's fix `cut` and `depth`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5339e2-e6ff-4ae2-95b7-5373b8bede3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "const cutOrder = ['Fair', 'Good', 'Very Good', 'Premium', 'Ideal'];\n",
    "const cutToScore = new Map(cutOrder.map((name, idx) => [name, idx]));\n",
    "const diamondsWithCutScore = diamondsTable\n",
    "  .objects()\n",
    "  .filter((row) => cutToScore.has(row.cut))\n",
    "  .map((row) => ({\n",
    "    ...row,\n",
    "    cut: cutToScore.get(row.cut)\n",
    "  }));\n",
    "\n",
    "const diamondsDepthNum = diamondsWithCutScore.map(item => ({\n",
    "  ...item,\n",
    "  depth: parseFloat(item.depth) // string to float\n",
    "}));\n",
    "\n",
    "console.table(diamondsDepthNum.slice(0, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02388d9-9ab4-4994-95b3-7d7a21a7b7c2",
   "metadata": {},
   "source": [
    "For the rest of the preprocessing, the **recipe API** chains these transformations in a clean pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f3302c-7a6a-48d2-bb7e-7ab1debd657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "const recipeNumeric = ['carat', 'depth', 'table', 'x', 'y', 'z', 'cut'];\n",
    "const recipeCategorical = ['color', 'clarity'];\n",
    "\n",
    "const diamondsRecipe = ds.ml.recipe({\n",
    "    data: diamondsDepthNum,\n",
    "    X: [...recipeNumeric, ...recipeCategorical],\n",
    "    y: 'price',\n",
    "  })\n",
    "  .parseNumeric([...recipeNumeric, 'price'])\n",
    "  .oneHot(recipeCategorical, { dropFirst: false })\n",
    "  .scale(recipeNumeric)\n",
    "  .split({ ratio: 0.8, shuffle: true, seed: 123 });\n",
    "\n",
    "const diamondsRecipePrepped = diamondsRecipe.prep();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c922d3a-ced5-40b3-9acd-fafe622b2e07",
   "metadata": {},
   "source": [
    "We will run a small MLP neural network with two layers of 32 neurons, a total of 64. This is tiny compared to hundreds of billion parameters of modern LLMs, but let's see if it's enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179cc283",
   "metadata": {},
   "outputs": [],
   "source": [
    "const diamondsMLP = new ds.ml.MLPRegressor({\n",
    "  hiddenLayers: [32, 32],\n",
    "  activation: 'relu',\n",
    "  learningRate: 1e-5,\n",
    "  epochs: 20,\n",
    "  batchSize: 512,\n",
    "  verbose: false\n",
    "});\n",
    "\n",
    "diamondsMLP.fit({\n",
    "  data: diamondsRecipePrepped.train.data,\n",
    "  X: diamondsRecipePrepped.train.X,\n",
    "  y: diamondsRecipePrepped.train.y\n",
    "});\n",
    "\n",
    "const diamondTestPredsRaw = diamondsMLP.predict({\n",
    "  data: diamondsRecipePrepped.test.data,\n",
    "  X: diamondsRecipePrepped.test.X\n",
    "});\n",
    "const diamondTestPreds = diamondTestPredsRaw.map((row) => row[0]);\n",
    "\n",
    "const diamondTestActual = diamondsRecipePrepped.test.data.map((row) => row.price);\n",
    "\n",
    "console.log('Test R²:', ds.ml.metrics.r2(diamondTestActual, diamondTestPreds).toFixed(3));\n",
    "console.log('Test MAE:', ds.ml.metrics.mae(diamondTestActual, diamondTestPreds).toFixed(0), '$');\n",
    "console.log('Test RMSE:', Math.sqrt(ds.ml.metrics.mse(diamondTestActual, diamondTestPreds)).toFixed(0), '$');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e900d3-b1b2-4c8f-9641-ac05a211f1e6",
   "metadata": {},
   "source": [
    "The R² computed on the test set is pretty high. The model has:\n",
    "- MAE (Mean Absolute Error): Average prediction error in dollars\n",
    "- RMSE (Root Mean Squared Error): Penalizes large errors more heavily\n",
    "\n",
    "Both metrics show the model predicts diamond prices reasonably well given the features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bf8d3c-a257-4bb2-9caf-f748c840cecd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "ML models find patterns in data. Garbage in, garbage out—data quality matters more than model complexity!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rps2kughxy7",
   "metadata": {},
   "source": [
    "## Ensemble\n",
    "\n",
    "Instead of relying on a single model, ensemble methods combine predictions from multiple models to improve accuracy and robustness (you might have read about ensemble methods from the previous section on clustering). This is the \"wisdom of crowds\" principle applied to machine learning, since different models make different mistakes. By combining them, we can reduce overfitting, improve generalization and capture different patterns. We do this with a `BranchPipeline`, which runs multiple models and combines their predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35lek2k9f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Create ensemble of different classifiers\n",
    "const ensembleClassifier = new ds.ml.BranchPipeline({\n",
    "  branches: {\n",
    "    knn: new ds.ml.KNNClassifier({ k: 10, weight: 'distance' }),\n",
    "    tree: new ds.ml.DecisionTreeClassifier({ maxDepth: 10 }),\n",
    "    forest: new ds.ml.RandomForestClassifier({ nTrees: 50, maxDepth: 10 })\n",
    "  },\n",
    "  combiner: 'vote'  // Majority voting for classification\n",
    "});\n",
    "\n",
    "// Fit all models (BranchPipeline expects array format)\n",
    "ensembleClassifier.fit(\n",
    "  penguinsTrainScaled.data.map(row => \n",
    "    penguinsFeatureFields.map(col => row[col])\n",
    "  ),\n",
    "  penguinsSplit.train.y  // encoded labels\n",
    ");\n",
    "\n",
    "// Predict with ensemble\n",
    "const ensemblePredictions = ensembleClassifier.predict(\n",
    "  penguinsTestScaled.data.map(row => \n",
    "    penguinsFeatureFields.map(col => row[col])\n",
    "  )\n",
    ");\n",
    "\n",
    "// Decode predictions using the original split's encoder\n",
    "const speciesEncoder = penguinsSplit.train.metadata.encoders.Species;\n",
    "const ensembleLabels = ensemblePredictions.map(idx => speciesEncoder.decode(idx));\n",
    "\n",
    "// Evaluate\n",
    "console.log('Ensemble Accuracy:', \n",
    "  ds.ml.metrics.accuracy(penguinsTrueSpecies, ensembleLabels).toFixed(3)\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uhhwpsabv69",
   "metadata": {},
   "source": [
    "One advantage of ensembles is the confidence measurement, telling how much do the models agree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x964yarzuv",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Check confidence for each prediction\n",
    "const ensembleConfidence = ensembleClassifier.confidence(\n",
    "  penguinsTestScaled.data.map(row => \n",
    "    penguinsFeatureFields.map(col => row[col])\n",
    "  )\n",
    ");\n",
    "\n",
    "// Show samples with low confidence (models disagree)\n",
    "console.log('Low confidence predictions (models disagree):');\n",
    "ensembleConfidence.forEach((conf, i) => {\n",
    "  if (conf < 0.8) {  // Less than 80% agreement\n",
    "    console.log(`  Sample ${i}: ${ensembleLabels[i]} (confidence: ${(conf * 100).toFixed(0)}%)`);\n",
    "  }\n",
    "});\n",
    "\n",
    "// Overall agreement\n",
    "const avgConfidence = ensembleConfidence.reduce((a, b) => a + b) / ensembleConfidence.length;\n",
    "console.log(`\\nAverage ensemble confidence: ${(avgConfidence * 100).toFixed(1)}%`);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8gzkxflay7m",
   "metadata": {},
   "source": [
    "BranchPipeline supports different ways to combine predictions:\n",
    "\n",
    "| Combiner | Use Case | How it works |\n",
    "|----------|----------|--------------|\n",
    "| `'vote'` | Classification | Majority vote wins |\n",
    "| `'weighted_vote'` | Classification | Weighted majority (better models count more) |\n",
    "| `'average'` | Regression | Average predictions |\n",
    "| `'max'` / `'min'` | Regression | Take maximum/minimum prediction |\n",
    "| Custom function | Any | Full control over combination logic |\n",
    "\n",
    "For regression (predicting numbers),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vhggddk8rs",
   "metadata": {},
   "outputs": [],
   "source": [
    "// Ensemble for regression (diamond prices)\n",
    "const ensembleRegressor = new ds.ml.BranchPipeline({\n",
    "  branches: {\n",
    "    knn: new ds.ml.KNNRegressor({ k: 10 }),\n",
    "    tree: new ds.ml.DecisionTreeRegressor({ maxDepth: 15 }),\n",
    "    forest: new ds.ml.RandomForestRegressor({ nTrees: 50, maxDepth: 15 })\n",
    "  },\n",
    "  combiner: 'average'  // Average predictions for regression\n",
    "});\n",
    "\n",
    "// Prepare data as arrays (models expect numeric arrays)\n",
    "const XtrainDiamonds = diamondsRecipePrepped.train.data.map(row =>\n",
    "  diamondsRecipePrepped.train.X.map(col => row[col])\n",
    ");\n",
    "const ytrainDiamonds = diamondsRecipePrepped.train.data.map(row => row.price);\n",
    "\n",
    "const XtestDiamonds = diamondsRecipePrepped.test.data.map(row =>\n",
    "  diamondsRecipePrepped.test.X.map(col => row[col])\n",
    ");\n",
    "const ytestDiamonds = diamondsRecipePrepped.test.data.map(row => row.price);\n",
    "\n",
    "// Fit ensemble\n",
    "ensembleRegressor.fit(XtrainDiamonds, ytrainDiamonds);\n",
    "\n",
    "// Predict\n",
    "const ensembleDiamondPreds = ensembleRegressor.predict(XtestDiamonds);\n",
    "\n",
    "// Evaluate\n",
    "console.log('Ensemble R²:', ds.ml.metrics.r2(ytestDiamonds, ensembleDiamondPreds).toFixed(3));\n",
    "console.log('Ensemble MAE:', ds.ml.metrics.mae(ytestDiamonds, ensembleDiamondPreds).toFixed(0));\n",
    "\n",
    "// Compare to single MLP\n",
    "console.log('\\nSingle MLP R²:', ds.ml.metrics.r2(diamondTestActual, diamondTestPreds).toFixed(3));\n",
    "console.log('Single MLP MAE:', ds.ml.metrics.mae(diamondTestActual, diamondTestPreds).toFixed(0));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
